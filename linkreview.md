| Название | Год | Ссылка | Краткое содержание | Тэги |
| -------- |---- | ------ | ------------------ | ---- |
| ✅✅ Language agents achieve superhuman synthesis of scientific knowledge | 2024 | [link](https://arxiv.org/pdf/2409.13740?) | Пример достижения лучшего качества на задачах, требующих поиска в сети с использованием похожих подходов. Используются LLM. Рассматривается задача суммаризации. Нужно сравниваться. Так как планируем уменьшать размер - достаточно быть рядом по качеству | scientific_tasks, agents |
| WebRL: Training LLM Web Agents via Self-Evolving Online Curriculum Reinforcement Learning | 2024 | [link](https://arxiv.org/pdf/2411.02337) | Уменьшили размер модели без просадок качества на задачах поиска. Источник хороших идей для RL / повышения качества. Сравнения избегать (Другая задача + уже проделана большая работа по мозданию эффективной модели маленького размера ) | scientific_tasks, rl, agents, small_models |
| ✅✅ ChatCite: LLM Agent with Human Workflow Guidance for Comparative Literature Summary | 2024 | [link](https://arxiv.org/abs/2403.02574) | Пайплайн для суммаризации, являющимся переходным к применению агентов. Все еще взаимодействие моделей довольно регламентировано, нет использования Нет использования инструментов (добавлена только многошаговая верификация). Стоит сравниваться | scientific_tasks, agents |
| HIAGENT: Hierarchical Working Memory Management for Solving Long-Horizon Agent Tasks with Large Language Model | 2024 | [link](https://arxiv.org/abs/2408.09559) | Разбирает использование памяти для задач, подразумевающих обработку длинного контекста. Релевантно для выбора архитектуры агента и внесения небольших изменений в другие архитектуры | scientific_tasks, agents |
| ✅✅ Chain of Agents: Large Language Models Collaborating on Long-Context Tasks | 2024 | [link](https://proceedings.neurips.cc/paper_files/paper/2024/hash/ee71a4b14ec26710b39ee6be113d7750-Abstract-Conference.html) | Применение агентов к близким задачам, нет использования Нет использования инструментов, фокус направлен на построение эффективного пайплайна совместной работы нескольких моделей. Стоит попробовать сравниваться. Опять же цель - приблизится, так как есть возможность выигравать по размерам | scientific_tasks, agents |
| ✅✅ Aligning LLM Agents by Learning Latent Preference from User Edits | 2024 | [link](https://proceedings.neurips.cc/paper_files/paper/2024/hash/f75744612447126da06767daecce1a84-Abstract-Conference.html) | Решается задача суммаризации при помощи RL на изменения, которые человек вносит в ответ. Стоит попробовать сравниваться. Можно взять идею для конструирования ревардов. Нет использования инструментов | scientific_tasks, rl, reward_construction |
| A Comprehensive Survey on Process-Oriented Automatic Text Summarization with Exploration of LLM-Based Methods | 2025 | [link](https://arxiv.org/abs/2403.02901) | Обзор истории развития методов решения задач суммаризации. Можно брать методы-бейзлайны для обоснования необходимости применимости агента в задаче | scientific_tasks |
| Learning to summarize with human feedback | 2020 | [link](https://proceedings.neurips.cc/paper/2020/hash/1f89885d556929e98d3ef9b86448f951-Abstract.html) | Начальное применения RL к рассматриваемым задачам. Можно сравниваться по некотрым метрикам | scientific_tasks, rl, reward_construction |
| ✅✅? Training language models to follow instructions with human feedback | 2022 | [link](https://proceedings.neurips.cc/paper_files/paper/2022/hash/b1efde53be364a73914f58805a001731-Abstract-Conference.html) | Оригинальный RLHF на задачу суммаризации. Сравниваться теоретически можно, но не факт что такая возможность доступна. Хорошая техническая основа | scientific_tasks, rl, reward_construction |
| A Survey on LLM-as-a-Judge | 2025 | [link](https://arxiv.org/abs/2411.15594) | Обзорная статья для более широкого взгляда на LLM as a judje | scientific_tasks, rl, reward_construction |
| Self-Rewarding Language Models | 2025 | [link](http://readwise-assets.s3.amazonaws.com/media/wisereads/articles/self-rewarding-language-models/2401.10020.pdf) | Подход к конструированию функции награды | rl, reward_construction |
| RLAIF vs. RLHF: Scaling Reinforcement Learning from Human Feedback with AI Feedback | 2024 | [link](https://arxiv.org/abs/2309.00267) | Техническая основа для использования LLM для конструирования реворда, оценивающего предпочтения. Очень важно из-за недостатка человеческого ресурса | rl, reward_construction |
| A Survey of Reinforcement Learning from Human Feedback | 2024 | [link](https://epub.ub.uni-muenchen.de/125328/1/2312.14925v2.pdf) | Обзорная статья по RLHF для большего контекста | rl, reward_construction |
| From RAG to Multi-Agent Systems: A Survey of Modern Approaches in LLM Development | 2025 | [link](https://www.preprints.org/frontend/manuscript/12d92f418fc17b4bd3e6b6144acf951c/download_pub) | Обзор истории развития методов решения задач суммаризации. Можно брать методы-бейзлайны для обоснования необходимости применимости агента в задаче | scientific_tasks |
| Enhancing Text Summarization with Linguistic Prompting and Reinforcement Learning: A Human-Centered Approach | 2024 | [link](https://hrcak.srce.hr/clanak/463019) | В некотором плане схожа со статьей про RL на исправлениях генераций. Вместо RLHF на награду, определяющую предпочтения - многошаговый пайплайн получения отклика от среды | scientific_tasks, rl, reward_construction |
| A Comparative Study of Quality Evaluation Methods for Text Summarization | 2024 | [link](https://arxiv.org/abs/2407.00747) | Обзор методов оценки суммаризаций. Нужен чтобы сравниться и убедиться, что не пропущены популярные методы | evaluation |
| NexusSum: Hierarchical LLM Agents for Long-Form Narrative Summarization | 2025 | [link](https://arxiv.org/abs/2505.24575) | Работа с длинными контекстами при помощи агентов. Сходство с решаемой задачей. Источник конструктивных идей | scientific_tasks, agents |
| Multi-LLM Text Summarization | 2025 | [link](https://arxiv.org/abs/2412.15487) | Мультиагентный подход к суммаризации. Нет RL. Стоит попробовать сравниваться | scientific_tasks, agents |
| ❌ Cradle: Empowering Foundation Agents Towards General Computer Control | 2024 | [link](https://arxiv.org/abs/2403.03186) | Статья по foundational agents. Рассматривалась как источник технических решений для реализации памяти агента. Нерелевантна из-за слишком далекой задачи | agents |
| ❌ VERA: Validation and Evaluation of Retrieval-Augmented Systems | 2024 | [link](https://arxiv.org/abs/2409.03759) | Система оценки RAG. Казалось, что можно обобщить на часть задач агентов. Пока признана нерелевантной | evaluation |
| ❌ CYGENT: A cybersecurity conversational agent with log summarization powered by GPT-3 | 2024 | [link](https://ieeexplore.ieee.org/abstract/document/10574658) | Применение агентов в суммаризации. Рассматривалась как потенциальный бейзлайн. Нерелевантна из-за далекой задачи | scientific_tasks, agents |
| PubMedQA: A Dataset for Biomedical Research Question Answering | 2019 | [link](https://arxiv.org/abs/1909.06146) | Один из вариантов валидации. Проверяем как наш агент с инструментами и памятью справляется с да/нет/возможно-QA по научным текстам (вне обучающего домена?) | evaluation |
| A Dataset of Information-Seeking Questions and Answers Anchored in Research Papers | 2021 | [link](https://arxiv.org/abs/2105.03011) | Продвинутый способ оценки извлечения информации из источников. Необходим, так как именно такие метрики сильнее всего можно улучшать применяя агентский подход | evaluation |
| ❌ AutoPatent: A Multi-Agent Framework for Automatic Patent Generation | 2024 | [link](https://arxiv.org/abs/2412.09796) | Применение агентов в суммаризации. Рассматривалась как потенциальный бейзлайн. Нерелевантна из-за далекой задачи | scientific_tasks, agents |
| Benchmarking Computer Science Survey Generation | 2025 | [link](https://arxiv.org/abs/2508.15658) | Продвинутый способ оценки извлечения информации из источников. Необходим, так как именно такие метрики сильнее всего можно улучшать применяя агентский подход. Особо интересен, так как оценивает не QA | evaluation |
| Hierarchical Catalogue Generation for Literature Review: A Benchmark | 2023 | [link](https://arxiv.org/abs/2304.03512) | Out of domain задача, но также является продвинутым способом оценки качества в задаче суммаризации | evaluation |
| SciReviewGen: A Large-scale Dataset for Automatic Literature Review Generation | 2023 | [link](https://arxiv.org/abs/2305.15186) | Продвинутый способ оценки извлечения информации из источников. Необходим, так как именно такие метрики сильнее всего можно улучшать применяя агентский подход. Особо интересен, так как оценивает не QA + Из-за размера имеет наибольшие шансы стать основой обучающей выборки | evaluation |
| LitLLMs, LLMs for Literature Review: Are we there yet? | 2025 | [link](https://arxiv.org/abs/2412.15249) | Обзор применения LLM к интересующей задаче | scientific_tasks |
| PlainQAFact: Retrieval-augmented Factual Consistency Evaluation Metric for Biomedical Plain Language Summarization | 2025 | [link](https://www.researchgate.net/profile/Zhiwen-You-3/publication/389785807_PlainQAFact_Retrieval-augmented_Factual_Consistency_Evaluation_Metric_for_Biomedical_Plain_Language_Summarization/links/68c99e234eef4b024b8bd825/PlainQAFact-Retrieval-augmented-Factual-Consistency-Evaluation-Metric-for-Biomedical-Plain-Language-Summarization.pdf) | Автометрика фактуальности. Может применяться в оценке / в конструировании функции награды | evaluation |
| QAFactEval: Improved QA-Based Factual Consistency Evaluation for Summarization | 2022 | [link](https://arxiv.org/abs/2112.08542) | В статье оптимизированы подходы к созданию основанной на QA метрики для оценки фактологической точности суммаризаций. Стоит использовать в оценке / конструировании функции награды | evaluation |
| Multi-XScience: A Large-scale Dataset for Extreme Multi-document Summarization of Scientific Articles | 2020 | [link](https://arxiv.org/abs/2010.14235) | Датасет к задаче многодокументной суммаризации (или составления научных обзоров, если принимать во внимание методику составления). Можно применять как базу для обучения / использовать предложенные подходы для создания собственных наборов данных | evaluation |
| A Tale of Evaluating Factual Consistency: Case Study on Long Document Summarization Evaluation | 2025 | [link](https://aclanthology.org/2025.findings-acl.648/) | Изучены возможности систем оценивания фактологической точности генераций. Предложены модификации. Стоит использовать в оценке / конструировании функции награды | evaluation |
| TLDR: Extreme Summarization of Scientific Documents | 2020 | [link](https://arxiv.org/abs/2004.15011) | Набор высококачественные и очень коротких суммаризаций. Может быть использован для оценки алгоритма на ood. Оказалась не очень релевантной (научный обзоры явно не стоит укорачивать)  | evaluation |
| Position: Episodic Memory is the Missing Piece for Long-Term LLM Agents | 2025 | [link](https://arxiv.org/abs/2502.06975) | Вводит новый вид памяти для агентов, который может повысить качество на нашей задаче. Используем при конструировании среды | agents |
| MemGPT: Towards LLMs as Operating Systems | 2024 | [link](https://par.nsf.gov/servlets/purl/10524107) | Иерархическая модификация памяти агентов. Может быть полезна в виду нацеленности на решение сложной задачи, требующей работы (и неоднократного обращения) к длинным контекстам | agents |
| Large Language Model Agent: A Survey on Methodology, Applications and Challenges | 2025 | [link](https://arxiv.org/abs/2503.21460) | Обзорная статья для LLM агентов. Сверяемся что ничего не было забыто | agents |
| AriGraph: Learning Knowledge Graph World Models with Episodic Memory for LLM Agents | 2024 | [link](https://arxiv.org/abs/2407.04363) | Графовая модификация памяти агентов. Может быть полезна в виду нацеленности на решение сложной задачи, требующей работы (и неоднократного обращения) к длинным контекстам | agents |
| Large Language Model based Multi-Agents: A Survey of Progress and Challenges | 2024 | [link](https://arxiv.org/abs/2402.01680) | Обзорная статья для мультиагентных LLM систем. Сверяемся что ничего не было забыто | agents |
| Advances and Challenges in Foundation Agents: From Brain-Inspired Intelligence to Evolutionary, Collaborative, and Safe Systems | 2025 | [link](https://arxiv.org/abs/2504.01990) | Статья, раскрывающая тему агентов, вдохновленных человеческим мышлением, а также направления развития. Полезна как обзорная | agents |
| Agent Planning with World Knowledge Model | 2024 | [link](https://proceedings.neurips.cc/paper_files/paper/2024/hash/d032263772946dd5026e7f3cd22bce5b-Abstract-Conference.html) | Метод получения эффективных и легковесных (соответсвтует главной идее работы) планировщиков, сравнимых по качеству с LLM. Может быть взята в основу конструирования планировщика | agents |
| Learn-by-interact: A Data-Centric Framework for Self-Adaptive Agents in Realistic Environments | 2025 | [link](https://arxiv.org/abs/2501.10893) | Фреймворк для обучения агентов. Может быть использован как образец или отправная точка | agents |
| Understanding the planning of LLM agents: A survey | 2024 | [link](https://www.researchgate.net/profile/Xu-Huang-37/publication/380756642_Understanding_the_planning_of_LLM_agents_A_survey/links/664d5a9dbc86444c72f64b6f/Understanding-the-planning-of-LLM-agents-A-survey.pdf) | Обзор по методам реализации планирования в агентах. | agents |
| ✅✅? ReAct: Synergizing Reasoning and Acting in Language Models | 2023 | [link](https://arxiv.org/abs/2210.03629?utm_source=chatgpt.com) | Технологическая основа использования моделями инструментов. Сравниваться напрямую скорее всего нет возможности, но можно сделать свою реаллизацию и провести сравнения в рамках ablation study | agents |
| AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation | 2023 | [link](https://arxiv.org/abs/2308.08155?utm_source=chatgpt.com) | Мультиагентный подход к решению произвольных задач. Используем как один из бейзлайнов | agents |
| Reflexion: Language Agents with Verbal Reinforcement Learning | 2023 | [link](https://arxiv.org/pdf/2303.11366) | Базовая архитектура агента с валидацией ответов и двумя видами памяти - краткосрочной и долгосрочной. Хотим применять к конкретной задаче | agents |